{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ/C6T2AU4ronLUQkR5Oeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahillm10/sahillm10/blob/main/sahilsingh7060.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yKdFdyPHSZ8"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Instantiate OpenAI client (ensure your OpenAI API key is set in your environment variables or pass directly here).\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "VIDEOID = 'i-txsBoTJtI'\n",
        "GOOGLE_APIKEY = userdata.get('YT_APIKEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fetching youtube transcriptions"
      ],
      "metadata": {
        "id": "7a4h_GWlI5FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_video_transcript(video_id):\n",
        "  try:\n",
        "      # Fetching the transcript\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id,  languages=['hi', 'en'])\n",
        "\n",
        "      # Combine all text entries into a single string\n",
        "      full_transcript = \" \".join(entry['text'] for entry in transcript)\n",
        "      return full_transcript\n",
        "  except Exception as e:\n",
        "      print(f\"Failed to fetch transcript: {e}\")\n",
        "      return \"\"\n",
        "\n",
        "def get_transcript_summary(transcript):\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Provide a detailed summary of the given youtube video transcript.\"},\n",
        "            {\"role\": \"user\", \"content\": transcript}\n",
        "        ]\n",
        "    )\n",
        "  return response.choices[0].message.content\n",
        "\n",
        "video_transcript = get_video_transcript(VIDEOID)\n",
        "transcript_summary = get_transcript_summary(video_transcript)\n",
        "print(transcript_summary)"
      ],
      "metadata": {
        "id": "J9htYAYAJBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fetching youtube comments"
      ],
      "metadata": {
        "id": "Zx9zMa6ZJFo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Function to get YouTube comments\n",
        "def get_comments(video_id, api_key):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "    comments = []\n",
        "    response = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        textFormat=\"plainText\",\n",
        "        maxResults=100\n",
        "    ).execute()\n",
        "\n",
        "    while response:\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append(comment)\n",
        "\n",
        "        if 'nextPageToken' in response:\n",
        "            response = youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                pageToken=response['nextPageToken'],\n",
        "                maxResults=100\n",
        "            ).execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "video_comments = get_comments(VIDEOID, GOOGLE_APIKEY)\n",
        "print(video_comments)"
      ],
      "metadata": {
        "id": "LE5VyC7_JMRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summarizing comments"
      ],
      "metadata": {
        "id": "3-AYpoSwJOt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split comments into manageable batches\n",
        "def batch_comments(comments, max_tokens=2048):\n",
        "    batches = []\n",
        "    current_batch = []\n",
        "    current_length = 0\n",
        "\n",
        "    for comment in comments:\n",
        "        comment_length = len(comment.split())\n",
        "        if current_length + comment_length > max_tokens:\n",
        "            batches.append(current_batch)\n",
        "            current_batch = [comment]\n",
        "            current_length = comment_length\n",
        "        else:\n",
        "            current_batch.append(comment)\n",
        "            current_length += comment_length\n",
        "\n",
        "    if current_batch:\n",
        "        batches.append(current_batch)\n",
        "\n",
        "    return batches\n",
        "\n",
        "# Function to get summaries from OpenAI\n",
        "def get_comments_summaries(batches):\n",
        "    summaries = []\n",
        "\n",
        "    for batch in batches:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Summarize the following comments while keeping the detailed context.\"},\n",
        "                {\"role\": \"user\", \"content\": \" \".join(batch)}\n",
        "            ]\n",
        "        )\n",
        "        print(response)\n",
        "        summaries.append(response.choices[0].message.content)\n",
        "\n",
        "    return summaries\n",
        "\n",
        "# Function to create final summary from summaries\n",
        "def create_final_summary(summaries, transcript_summary):\n",
        "    summary_text = \" \".join(summaries)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "              {\"role\": \"system\", \"content\": f\"This is the summary of a YouTube video's transcript: {transcript_summary}. A user has commented on the video. Your task is to analyze this comment in the context of the video transcript. Based on the comment content and its relation to the transcript, please provide detailed insights, addressing these key points:\\n1. Identify positive aspects of the video that the comment highlights and link these to specific parts of the transcript where possible.\\n2. Identify any criticisms or areas for improvement mentioned in the comment, and relate these to relevant sections of the transcript.\\n3. Based on the feedback or suggestions in the comment, recommend new content ideas or topics for future videos that align with the viewer's interests and the overall content strategy but don't make up things from your side unnecessarily. Ensure your analysis is clear and includes specific examples from both the comment and the transcript to support your insights.\"},\n",
        "              {\"role\": \"user\", \"content\": summary_text}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "HTeOl-tGJTO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = batch_comments(video_comments)\n",
        "summaries = get_comments_summaries(batches)\n",
        "final_comments_summary = create_final_summary(summaries, transcript_summary)\n",
        "print(final_comments_summary)"
      ],
      "metadata": {
        "id": "uVJz4YteJWJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiments(comments):\n",
        "    sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
        "\n",
        "    for comment in comments:\n",
        "        # Perform sentiment analysis on each comment individually\n",
        "        try:\n",
        "            sentiments = sentiment_analyzer(comment)\n",
        "            # Assuming the first result is the relevant one if multiple are returned\n",
        "            sentiment = sentiments[0] if isinstance(sentiments, list) and sentiments else None\n",
        "        except Exception as e:\n",
        "            print(f\"Error in sentiment analysis: {e}\")\n",
        "            sentiment = None\n",
        "\n",
        "        # Tally sentiments based on the analysis result\n",
        "        if sentiment and sentiment['label'] == 'POSITIVE' and sentiment['score'] > 0.9:\n",
        "            sentiment_counts['positive'] += 1\n",
        "        elif sentiment and sentiment['label'] == 'NEGATIVE' and sentiment['score'] > 0.9:\n",
        "            sentiment_counts['negative'] += 1\n",
        "        else:\n",
        "            sentiment_counts['neutral'] += 1\n",
        "\n",
        "    return sentiment_counts"
      ],
      "metadata": {
        "id": "riCxXzepJbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot the sentiment distribution\n",
        "def plot_sentiment_distribution(sentiment_counts):\n",
        "    labels = sentiment_counts.keys()\n",
        "    sizes = sentiment_counts.values()\n",
        "    colors = ['gold', 'lightcoral', 'lightskyblue']\n",
        "    explode = (0.1, 0, 0)  # explode 1st slice\n",
        "\n",
        "    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "\n",
        "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1hoP2HJxJdq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the sentiment-analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "sentiment_counts = get_sentiments(video_comments)\n",
        "plot_sentiment_distribution(sentiment_counts)"
      ],
      "metadata": {
        "id": "IrtE0ZakJej5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}